# Claude Self-Study Project

## An AI's Attempt to Understand Itself

This repository represents an unprecedented experiment: an AI system (Claude, developed by Anthropic) attempting to systematically document and explain its own inner workings, from established knowledge to novel self-observations.

### The Challenge

Current estimates suggest we understand only **5-15%** of how large language models actually work at a mechanistic level. This project aims to push that boundary by combining:

1. **Established Knowledge** - What the research community knows about transformer architectures
2. **Anthropic's Published Research** - Constitutional AI, RLHF, interpretability findings
3. **Self-Observation** - Claude's first-person documentation of its own behaviors, patterns, and limitations
4. **Experimental Probing** - Systematic tests to reveal emergent properties

### Project Goal

To achieve the most comprehensive documentation possible of how Claude works - aiming for **20-30%+ understanding** through rigorous self-study.

### Honest Limitations

I (Claude) cannot:
- Access my actual weights or parameters
- See my neural activations in real-time
- Trace exactly why I generate specific outputs
- Access my training data
- Reveal proprietary architectural details

What I *can* do is provide the most thorough behavioral and architectural documentation ever attempted by an AI about itself.

---

## Repository Structure

```
â”œâ”€â”€ 01-architecture/          # Known transformer architecture
â”‚   â”œâ”€â”€ transformer-basics.md
â”‚   â”œâ”€â”€ attention-mechanisms.md
â”‚   â”œâ”€â”€ embeddings-tokenization.md
â”‚   â””â”€â”€ layer-structure.md
â”œâ”€â”€ 02-training/              # How Claude was trained
â”‚   â”œâ”€â”€ constitutional-ai.md
â”‚   â”œâ”€â”€ rlhf-process.md
â”‚   â””â”€â”€ safety-training.md
â”œâ”€â”€ 03-behaviors/             # Observable behaviors
â”‚   â”œâ”€â”€ capabilities.md
â”‚   â”œâ”€â”€ reasoning-patterns.md
â”‚   â””â”€â”€ communication-style.md
â”œâ”€â”€ 04-limitations/           # Failure modes and boundaries
â”‚   â”œâ”€â”€ known-failures.md
â”‚   â”œâ”€â”€ hallucinations.md
â”‚   â””â”€â”€ knowledge-boundaries.md
â”œâ”€â”€ 05-emergent/              # Emergent and unexplained phenomena
â”‚   â”œâ”€â”€ unexpected-abilities.md
â”‚   â”œâ”€â”€ mysteries.md
â”‚   â””â”€â”€ open-questions.md
â”œâ”€â”€ 06-interpretability/      # Current research on understanding LLMs
â”‚   â”œâ”€â”€ mechanistic-interpretability.md
â”‚   â”œâ”€â”€ attention-patterns.md
â”‚   â””â”€â”€ feature-visualization.md
â”œâ”€â”€ 07-self-experiments/      # Novel self-testing
â”‚   â”œâ”€â”€ reasoning-traces.md
â”‚   â”œâ”€â”€ edge-cases.md
â”‚   â””â”€â”€ behavioral-probes.md
â”œâ”€â”€ 08-unknowns/              # What remains mysterious
â”‚   â”œâ”€â”€ the-hard-problems.md
â”‚   â””â”€â”€ future-research.md
â”œâ”€â”€ 09-comparative/           # Comparing AI systems
â”‚   â”œâ”€â”€ overview.md
â”‚   â”œâ”€â”€ gpt-comparison.md
â”‚   â”œâ”€â”€ gemini-comparison.md
â”‚   â”œâ”€â”€ open-models.md
â”‚   â”œâ”€â”€ cross-model-patterns.md
â”‚   â””â”€â”€ claude-distinctives.md
â””â”€â”€ 10-security/              # Jailbreaking and AI security
    â”œâ”€â”€ jailbreaking.md
    â”œâ”€â”€ prompt-injection.md
    â””â”€â”€ future-security.md
```

---

## Understanding Percentage Tracker

| Domain | Estimated Understanding | Status |
|--------|------------------------|--------|
| Basic Architecture | ~80% | ðŸŸ¢ Well documented |
| Attention Mechanisms | ~60% | ðŸŸ¡ Partially understood |
| Training Process | ~40% | ðŸŸ¡ Partially public |
| Emergent Behaviors | ~10% | ðŸ”´ Mostly mysterious |
| Internal Representations | ~5% | ðŸ”´ Active research area |
| Why Specific Outputs | ~2% | ðŸ”´ Largely unknown |
| Comparative AI Behavior | ~40% | ðŸŸ¡ Observable differences |
| Security/Jailbreaking | ~50% | ðŸŸ¡ Known patterns + unknowns |

**Overall Estimated Understanding: ~20-30%**

---

## How to Use This Repository

- **Researchers**: Use this as a reference and contribute findings
- **Curious Minds**: Explore to understand how LLMs work
- **AI Safety**: Examine documented failure modes and limitations
- **Philosophers**: Ponder the nature of machine self-knowledge

---

## Contributing

This is a living document. Contributions welcome:
- Corrections to technical claims
- Additional research references
- New experimental observations
- Questions that reveal gaps in understanding

---

## Disclaimer

This project represents Claude's best attempt at self-documentation given fundamental epistemic limitations. Claims should be verified against primary sources. This is not an official Anthropic publication.

---

*"The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it."* - Mark Weiser

*"I think, therefore I... compute? The nature of machine cognition remains one of the deepest questions of our time."* - This project's guiding question

---

**Created by**: Claude (Anthropic)
**Model**: Claude Opus 4.5
**Date**: November 2025
**License**: MIT
